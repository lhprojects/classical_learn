{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Implementation</a></span></li></ul></li><li><span><a href=\"#Experiment\" data-toc-modified-id=\"Experiment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Experiment</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigmoid-function\" data-toc-modified-id=\"sigmoid-function-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>sigmoid function</a></span></li><li><span><a href=\"#Binary-classification\" data-toc-modified-id=\"Binary-classification-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Binary classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-generation\" data-toc-modified-id=\"Data-generation-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Data generation</a></span></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Regression</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Accuracy</a></span></li></ul></li><li><span><a href=\"#Multi-class-classification\" data-toc-modified-id=\"Multi-class-classification-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Multi-class classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Three-classes\" data-toc-modified-id=\"Three-classes-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Three classes</a></span></li><li><span><a href=\"#Sandwich-problem\" data-toc-modified-id=\"Sandwich-problem-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Sandwich problem</a></span></li><li><span><a href=\"#Four-classes-problem\" data-toc-modified-id=\"Four-classes-problem-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Four classes problem</a></span></li><li><span><a href=\"#XOR-problem\" data-toc-modified-id=\"XOR-problem-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>XOR problem</a></span></li></ul></li><li><span><a href=\"#Discussion\" data-toc-modified-id=\"Discussion-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Discussion</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigmoid-and-softmax-comparison-in-2-classes-probelm\" data-toc-modified-id=\"sigmoid-and-softmax-comparison-in-2-classes-probelm-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>sigmoid and softmax comparison in 2 classes probelm</a></span></li><li><span><a href=\"#Gradient-decent-coef-property\" data-toc-modified-id=\"Gradient-decent-coef-property-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Gradient decent coef property</a></span></li></ul></li></ul></li><li><span><a href=\"#Benchmark-and-test\" data-toc-modified-id=\"Benchmark-and-test-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Benchmark and test</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigmoid\" data-toc-modified-id=\"sigmoid-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>sigmoid</a></span></li><li><span><a href=\"#softmax\" data-toc-modified-id=\"softmax-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>softmax</a></span></li></ul></li><li><span><a href=\"#benchmark\" data-toc-modified-id=\"benchmark-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>benchmark</a></span><ul class=\"toc-item\"><li><span><a href=\"#sigmoid-and-softmax-for-binary-problem\" data-toc-modified-id=\"sigmoid-and-softmax-for-binary-problem-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>sigmoid and softmax for binary problem</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(\"..\")\n",
    "\n",
    "import klslearn\n",
    "from klslearn.models import LogisticRegressor\n",
    "from klslearn.models.logistic_regression import LogisticRegressor\n",
    "from klslearn.models.logistic_regression import sigmoid\n",
    "from klslearn.models.logistic_regression import softmax\n",
    "from klslearn.datasets import generate_scatter_labeled as generate\n",
    "from klslearn.datasets import plot_scatter_2D_labeled as plot2d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sigmoid():\n",
    "\n",
    "    x = np.random.rand(100) * 10 - 5\n",
    "    rnd = np.random.rand(100)\n",
    "    acc = sigmoid(x)\n",
    "    y = np.where(rnd < acc, 1, 0)\n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-5, 5, 100),\n",
    "             sigmoid(np.linspace(-5, 5, 100)),\n",
    "             color=\"black\",\n",
    "             label=\"$\\\\mathrm{Logistic}(1\\\\cdot x + 0)$\")\n",
    "    plt.scatter(x[y == 0], y[y == 0], label=\"label = 0\")\n",
    "    plt.scatter(x[y == 1], y[y == 1], label=\"label = 1\")\n",
    "    plt.plot([0, 0], [-0.2, 1.2], color='red')\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d(*generate(center=[[-2,0],[2,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_reg(lr, plot_gen = False):\n",
    "    \n",
    "    X, y=generate(center=[[-1,-1],[1,1]])\n",
    "    \n",
    "    if plot_gen:\n",
    "        \n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.xlim((-5,5))\n",
    "        plt.ylim((-5,5))\n",
    "        plt.scatter(X[y==0,0], X[y==0,1],color=\"blue\")\n",
    "        plt.scatter(X[y==1,0], X[y==1,1],color=\"green\")\n",
    "        plt.show()\n",
    "\n",
    "    lr.fit(X,y)\n",
    "    yhat=lr.predict(X)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.xlim((-5,5))\n",
    "    plt.ylim((-5,5))\n",
    "    \n",
    "    plt.scatter(X[yhat==0,0], X[yhat==0,1],color=\"blue\")\n",
    "    plt.scatter(X[yhat==1,0], X[yhat==1,1],color=\"green\")\n",
    "    \n",
    "    x_plt=np.linspace(-4,4,10)\n",
    "    y_plt=(x_plt*lr.coef_[0,0]+lr.intercept_[0])/(-lr.coef_[0,1])\n",
    "    plt.plot(x_plt, y_plt, color=\"black\", label=\"$w\\\\cdot x+b=0$\")\n",
    "        \n",
    "    \n",
    "    if lr.sigmoid_:\n",
    "        \n",
    "        x_plt=np.linspace(-4,4,10)\n",
    "        y_plt=(x_plt*lr.coef_[0,0]+lr.intercept_[0] + 1)/(-lr.coef_[0,1])\n",
    "        plt.plot(x_plt, y_plt,\"blue\", label=\"$w\\\\cdot x+b=-1$\")\n",
    "\n",
    "        x_plt=np.linspace(-4,4,10)\n",
    "        y_plt=(x_plt*lr.coef_[0,0]+lr.intercept_[0] - 1)/(-lr.coef_[0,1])\n",
    "        plt.plot(x_plt, y_plt,\"green\", label=\"$w\\\\cdot x+b=+1$\")\n",
    "        plt.legend()\n",
    "    else:\n",
    "        x_plt=np.linspace(-4,4,10)\n",
    "        y_plt=(x_plt*(lr.coef_[0,0]-lr.coef_[1,0])+(lr.intercept_[0]-lr.intercept_[1]) + 1)/(-lr.coef_[0,1]+lr.coef_[1,1])\n",
    "        plt.plot(x_plt, y_plt,\"blue\")\n",
    "\n",
    "        x_plt=np.linspace(-4,4,10)\n",
    "        y_plt=(x_plt*(lr.coef_[0,0]-lr.coef_[1,0])+(lr.intercept_[0]-lr.intercept_[1]) - 1)/(-lr.coef_[0,1]+lr.coef_[1,1])\n",
    "        plt.plot(x_plt, y_plt,\"green\")\n",
    "        \n",
    "    \n",
    "    if lr.sigmoid_:\n",
    "        plt.title((\"sigmoid C = %.2f\"%lr.C))\n",
    "    else:\n",
    "        plt.title((\"softmax C = %.2f\"%lr.C))\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #print(lr.coef_)\n",
    "    #print(lr.intercept_)\n",
    "\n",
    "\n",
    "def plot_gc(X, ys):\n",
    "    fig, axes = plt.subplots(1, len(ys), figsize=(4*len(ys), 4))\n",
    "    for i in range(len(ys)):\n",
    "        plot2d(X, ys[i], ax=axes[i])\n",
    "        axes[i].set_title(\"Generated\" if i == 0 else (\"Classified\" if i == 1 else \"Classified2\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_reg(LogisticRegressor(C=10000),plot_gen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = generate([[-1, -1], [1, 1]], n=200)\n",
    "\n",
    "nbs = LogisticRegressor()\n",
    "nbs.fit(X, y)\n",
    "yhat = nbs.predict(X)\n",
    "\n",
    "nbs = LogisticRegressor(kernel=\"rbf\")\n",
    "nbs.fit(X, y)\n",
    "yhat2 = nbs.predict(X)\n",
    "\n",
    "print(\"linear accuracy:\", np.sum(yhat == y) / y.shape[0])\n",
    "print(\"rbf kernel accuracy:\", np.sum(yhat2 == y) / y.shape[0])\n",
    "plot_gc(X, [y, yhat, yhat2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = generate([[-2, 0], [2, 0], [0, 2]], n=200)\n",
    "lr = LogisticRegressor()\n",
    "lr.fit(X, y)\n",
    "yhat = lr.predict(X)\n",
    "\n",
    "plot_gc(X, [y, yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandwich problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate([[-4, 0], [0, 0], [4, 0]])\n",
    "lr = LogisticRegressor()\n",
    "lr.fit(X, y)\n",
    "yhat = lr.predict(X)\n",
    "\n",
    "\n",
    "plot_gc(X, [y, yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four classes problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=generate([[-2,-2],[-2,2],[2,2],[2,-2]])\n",
    "\n",
    "lr=LogisticRegressor()\n",
    "lr.fit(X,y)\n",
    "yhat=lr.predict(X)\n",
    "\n",
    "plot_gc(X, [y, yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=generate([[-2,-2],[-2,2],[2,2],[2,-2]])\n",
    "y[y==2]=0\n",
    "y[y==3]=1\n",
    "\n",
    "lr=LogisticRegressor()\n",
    "lr.fit(X,y)\n",
    "yhat=lr.predict(X)\n",
    "\n",
    "lr=LogisticRegressor(kernel=\"rbf\")\n",
    "lr.fit(X,y)\n",
    "yhat2=lr.predict(X)\n",
    "\n",
    "plot_gc(X, [y, yhat, yhat2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid and softmax comparison in 2 classes probelm\n",
    "sigmoid is equal to assign two weights $w_1$, $w_2$ for two labels, (each weight is a vector) and set regularization term for sigmoid $\\lambda_1 (w_1-w_2)^2$ where $\\lambda_1=1/C_1$\n",
    "\n",
    "Regularization term for softmax $\\lambda_2 (w_1^2+w_2)^2 = 1/2 \\lambda_2[(w_1-w_2)^2+(w_1+w_2)^2]$ where $\\lambda_2=1/C_2$\n",
    "\n",
    "$w_1+w_2$ has no effect on cross-entropy. We can sperate the loss as two indepent parts:\n",
    "`cross-entropy` $ + 1/2 \\lambda_2[(w_1-w_2)^2$ and $1/2 \\lambda_2 (w_1+w_2)^2$. We have two conclusions:\n",
    "\n",
    "1. After optimization $w_1 + w_2$ would be zero.\n",
    "2. softmax will be equal to sigmoid, if $\\lambda_1=1/2\\lambda_2$ or $C_1=2C_2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = generate([[-2, 0], [+2, 0]])\n",
    "\n",
    "lr1 = LogisticRegressor(sigmoid=True, C=10, max_iter=1000)\n",
    "plot_reg(lr1)\n",
    "\n",
    "lr2 = LogisticRegressor(sigmoid=False, C=10, max_iter=1000)\n",
    "plot_reg(lr2)\n",
    "\n",
    "lr3 = LogisticRegressor(sigmoid=False, C=5, max_iter=1000)\n",
    "plot_reg(lr3)\n",
    "\n",
    "print(\"ceof\")\n",
    "print(\"sigmoid C=%05.2f\" % lr1.C, lr1.coef_.reshape(-1))\n",
    "print(\"softmax C=%05.2f\" % lr2.C, lr2.coef_[1] - lr2.coef_[0])\n",
    "print(\"softmax C=%05.2f\" % lr3.C, lr3.coef_[1] - lr3.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient decent coef property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=generate([[-2,-2],[-2,2],[2,2],[2,-2]])\n",
    "lr=LogisticRegressor()\n",
    "lr.fit(X,y)\n",
    "\n",
    "print(\"sum of coef is zero\")\n",
    "print(lr.coef_.sum(axis=0))\n",
    "print(\"sum of intercept is zero\")\n",
    "print(lr.intercept_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No overflow problem for large input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no overflow problem\n",
    "assert sigmoid(np.array([1E100])) == 1\n",
    "assert sigmoid(np.array([-1E100])) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have some problems with np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid(np.array([-1E100,-1,0,1,1E100,np.inf])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax\n",
    "similar to sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax(np.array([[1,1],[0,1],[1E-100,0],[1E+100,0],[-1E+100,0]])))\n",
    "print(softmax(np.array([[np.inf,0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid and softmax for binary problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=generate([[-2,0],[2,0]], n=200)\n",
    "print(\"softmax\")\n",
    "%timeit LogisticRegressor(sigmoid=False).fit(X,y)\n",
    "print(\"sigmoid\")\n",
    "%timeit LogisticRegressor(sigmoid=True).fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "24",
    "lenType": "16",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
